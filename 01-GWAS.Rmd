# Analysis of Genetic Association Studies

*All information shown in this chapter has been extracted from the course "Analysis of Genetic Association Studies", taught at University of Liverpool, Department of Health Data Science.*


The purpose of this section is to provide guidance on performing a GWAS analysis step-by step, as well as introducing to useful software for undertaking a GWAS.

## Useful Linux commands

First, I'll show you some useful Linux commands for working with GWASs files.
Linux is an operating system very well suited to dealing with large datasets.

Create a bash script:
```{bash, eval=FALSE}
touch script.sh
```

Run the script:
```{bash, eval=FALSE}
sh script.sh
```

Return the number of lines of a file:
```{bash, eval=FALSE}
wc -l ./file.map
```

Print only the first 15 lines of "./file.map" file:
```{bash, eval=FALSE}
head -15 ./file.map
```

Print the bottom of the file:
```{bash, eval=FALSE}
tail -15 ./file.map
```

Find the SNP "rs1234":
```{bash, eval=FALSE}
grep "rs1234" ./file.map
```

Find the SNP "rs1234" and print the line number of the match:
```{bash, eval=FALSE}
grep -n "rs1234" ./file.map
```

Search the file ./file.map, for "1234" in the SNP name (column 2, specified by $2) and print the whole line:
```{bash, eval=FALSE}
awk '$2~/1234/{print}' ./file.map
```

Search the file ./file.map, for "1234" in the SNP position (column 4, specified by $4) and print only the SNP name (column 2):
```{bash, eval=FALSE}
awk '$4~/1234/{print $2}' ./file.map
```

Search for an exact match of "rs1234676" in the SNP name (column 2) and print the whole line:
```{bash, eval=FALSE}
awk '$2=="rs1234676"/{print}' ./file.map
```

Search for all SNPs with a position between 90680000 up to and including 90690000 in the SNP position column (column 4) and count the lines in that output:
```{bash, eval=FALSE}
awk '$4>90680000&&$4<=90690000{print}' ./file.map | wc -l
```

Remove the chromosome 10 from the output above:
```{bash, eval=FALSE}
awk '$4>90680000&&$4<=90690000{print}' ./file.map | awk '$1!=10{print}'
```

Count the SNPs from chromosome 10 and chromosome 23:
```{bash, eval=FALSE}
awk '$1==10{print}' ./file.map| wc -l
awk '$1==23{print}' ./file.map| wc -l
```

Print the SNP position of the first SNP on chromosome 23:
```{bash, eval=FALSE}
awk '$1==23{print $4}' ./file.map | head -1
```

There are SNPs starting with other characters than "rs", identify what other starting characters there are.
```{bash, eval=FALSE}
awk '$2!~/rs/{print $2}' ./file.map
awk '$2!~/rs/&&$2!~/.../{print $2}' ./file.map
```


## Useful R commands

NOTE: R has a system of libraries on the Comprehensive R Archive Network (CRAN) where R users deposit code to be verified and then distributed for wider use (https://cran.r-project.org/).

Load the file "./file.map" into R.
```{r, eval=FALSE}
gd <- read.table("./file.map",header=F)
names(gd)<-c("CHR","SNP","cM","BP")
head(gd)
tail(gd)
```

Search for only rs1234568 in the SNP name (column 2):
```{r, eval=FALSE}
gd[gd$SNP=="rs1234568",]
```

Search for all SNPs with a position between 90680000 up to and including 90690000 in the SNP position column:
```{r, eval=FALSE}
gd[gd$BP>90680000&gd$BP<=90690000,]
```

Do you have any genome-wide significant (p=5x10-8) SNPs?
```{r, eval=FALSE}
gd[gd$P<0.00000005,]
```

Report results using a Manhattan plot:
```{r, eval=FALSE}
plot(gd$BP,-log(gd$P,base=10))
```

There were SNPs from both chromosome 10 and 23 in the .map file. Separate chromosomes by colour:
```{r, eval=FALSE}
plot(gd$BP,-log(gd$P,base=10), col=gd$CHR)
```

Add a reference line to know which SNPs have a p-value below 1x10-5:
```{r, eval=FALSE}
plot(gd$BP,-log(gd$P,base=10), col=gd$CHR)
abline(h=-log(1e-5,base=10),col="blue")
```

Use the package "qqman" to generate a Manhattan plot:
```{r, eval=FALSE}
manhattan(gd)
manhattan(gd[gd$chromosome==10,], chr="chromosome",bp="position",snp="rsid",p="pvalue")
manhattan(gd[gd$chromosome==23,], chr="chromosome",bp="position",snp="rsid",p="pvalue")
```

## Variant Calling from sequencing data

### Generate genotype calls for a single sample

In this section we will generate genotype calls from aligned sequencing data, explore the calls and perform some initial quality checks.

A commonly used variant caller comes from the Genome Analysis Toolkit (GATK).

* GATK takes files containing aligned sequencing reads. These are called .bam files.
* GATK produces .vcf files containing details of the variants, to explore and manipulate these files, we'll be using vcftools. This is also freely available and can be found: http://vcftools.sourceforge.net/
* To visualise the variant calls we'll be using Integrated Genome Viewer (IGV); this is available from: http://software.broadinstitute.org/software/igv/

Usually, each .bam file has an accompanying .bai file. These are index files, which are programs used to navigate the data faster – they must be present for software programs to run. 

Generate genotype calls for the sample NA12878 using GATK:
```{bash, eval=FALSE}
gatk -T HaplotypeCaller \
-R human_g1k_b37_20.fasta \
-I NA12878_wgs_20.bam \
-o yourfilename.vcf \
-L 20:10,000,000-10,200,000
```

Variant calling on a whole genome can take a long time, we're only looking at a very small region: Chromosome 20, positions 10,000,000 – 10,200,000, specified by the –L option.

(*) Details of the different options used: https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_gatk_tools_walkers_haplotypecaller_HaplotypeCaller.php

To have a look at the first 5 variant calls using:
```{bash, eval=FALSE}
head -34 yourfilename.vcf | tail -6
```

Filter the vcf file and see only the variants called in the region 20:10,002,371-10,002,546:
```{bash, eval=FALSE}
vcftools --vcf yourfilename.vcf \
--chr 20 \
--from-bp 10002371 \
--to-bp 10002546 \
--out yournewfilename \
--recode
```

The code above will generate the files: yournewfilename.recode.vcf and yournewfilename.log.

To know how many variants were identified in this region:
```{bash, eval=FALSE}
cat yournewfilename.log
```

What are those variants?
```{bash, eval=FALSE}
cat yournewfilename.recode.vcf
```

### Generating genotypes from multiple .bam files

To generate genotypes for multiple samples, one option is to run the same command than above but give multiple -I options:
```{bash, eval=FALSE}
gatk -T HaplotypeCaller \
-R human_g1k_b37_20.fasta \
-I NA12878_wgs_20.bam \
-I NA12882_wgs_20.bam \
-I NA12877_wgs_20.bam \
-o differentfilename.vcf \
-L 20:10,000,000-10,200,000
```

Another option is to run each sample independently, but generate a .g.vcf file and then merge the .g.vcf files to get a single call set.

Generate a .g.vcf file for sample NA12878 (then run the same command on the bam files for samples NA12877 and NA12882):
```{bash, eval=FALSE}
gatk -T HaplotypeCaller \
-R human_g1k_b37_20.fasta \
-I NA12878_wgs_20.bam \
-o yourchoice_NA12878.g.vcf \
-ERC GVCF \
-L 20:10,000,000-10,200,000
```

The main difference between the .g.vcf and the .vcf file is that the gvcf file contains a line per base or region if the region contains no variants. The gvcf also includes <NON_REF> as a symbolic allele, this allows for complex variants at the site and to makes it possible to give a confidence measure in the reference allele (more info: http://gatkforums.broadinstitute.org/gatk/discussion/4017/what-is-a-gvcf-and-how-is-it-differentfrom-a-regular-vcf)


Merge the individual .g.vcf files and get a .vcf file containing the calls for all samples:
```{bash, eval=FALSE}
gatk -T GenotypeGVCFs \
-R human_g1k_b37_20.fasta \
-V yourchoice_NA12878.g.vcf \
-V yourchoice_NA12882.g.vcf \
-V yourchoice_NA12877.g.vcf \
-o yourchoice_gvcf_jointcalls.vcf \
-L 20:10,000,000-10,200,000
```

### Performing initial QC

GWAS studies often focus only on SNPS, whereas variant callers identify more variants, such as indels. To create a file containing just SNPs (no indels or other variants) the --remove-indels option from vcftools can be used:
```{bash, eval=FALSE}
vcftools --vcf yourchoice_gvcf_jointcalls.vcf \
--remove-indels \
--out yourchoice_snps \
--recode
```

Calculate the Ts/Tv ratio:
```{bash, eval=FALSE}
vcftools --vcf yourchoice_gvcf_jointcalls.vcf \
--TsTv-summary \
--out yourchoice_tstv
```

The QualByDepth (QD) score is the variant quality (QUAL field) divided by the unfiltered depth of nonreference samples. Variants with a low QD may be unreliable and have a high false positive rate. To add a filter to the .vcf file which flags variants which have a quality-by-depth less than 2.0:
```{bash, eval=FALSE}
gatk -T VariantFiltration \
-R human_g1k_b37_20.fasta \
-V yourchoice_gvcf_jointcalls.vcf \
--filterExpression 'QD<2.0' \
--filterName 'QualityDepth' \
-o yourchoice_flagged.vcf
```


NOTE: SNPs and Indels may need to be treated differently – to do this, the file can be first splitted into 2 vcfs, one containing SNPs and one containing indels, then add the flags should be added.

The new .vcf is now different from the original as the FILTER column is now filled in, usually with PASS.

Remove all SNPs with a filter flag other than PASS:
```{bash, eval=FALSE}
vcftools --vcf yourchoice_flagged.vcf \
--remove-filtered-all \
--recode \
--out yourchoice_filtered
```

To convert the SNP filtered .vcf file to PLINK .ped and .map files:
```{bash, eval=FALSE}
vcftools --vcf yourchoice_gvcf_jointcalls.vcf \
--remove-indels \
--out yourchoice_plink
```

## Quality Control for GWAS

### Software and datasets

A commonly used program for GWAS analysis is called 'PLINK', which is freely available for download. The webpage for PLINK is available at: http://pngu.mgh.harvard.edu/~purcell/plink/
For undertaking a GWAS, two input files are required: one '.ped' file and one '.map' file.

* The PED file is a white-space (space or tab) delimited file. It includes one row for each participant within the study, and at least seven columns. Each of the SNPs genotyped is represented by two columns (column 7 onwards) –one for each of the two alleles held by the individual at the SNP. Typical coding would be A, C, G or T to represent the four possible alleles, or similarly 1, 2, 3 or 4. Coding for missing genotype is '0 0'.
* The .map file includes information on the SNPs genotyped, and each row represents a SNP. It includes 4 columns.


In this example, we will be working on analysing the GWAS dataset 'genstudy' (a .map and .ped file for 'genstudy'). The study is a case-control study with 252 diseased (cases) and 252 non-diseased (controls) individuals.
All individuals have been genotyped for 198,684 SNPs on chromosome 10 and 22,379 SNPs on chromosome X. The purpose of the study is to try and identify SNPs on chromosome 10 associated
with disease.



To view the first row and first eight columns of the 'genstudy.ped' file:
```{bash, eval=FALSE}
awk 'FNR == 1 { print $1,$2,$3,$4,$5,$6,$7,$8} ' genstudy.ped
```

The eight columns correspond to the first six mandatory columns plus two columns representing the first SNP genotyped.


### Checking the input datasets

Before starting a genotype QC or GWAS association analysis, it is important to check that the input files are in good order, and contain the individuals and SNPs that we think they should. Do this by focussing on the SNPs on chromosome 10:
```{bash, eval=FALSE}
plink --file genstudy --chr 10 --noweb
```

The output will also be saved in a log file called 'plink.log'.

Note: the '-noweb' option is included to make PLINK run faster – otherwise it connects to the web to check for updates before running the analysis.

### Binary PED files

To save space and time, .map and .ped files can be converted to binary format. In doing this, we create three new files as follows:

* '.bed': file This includes all the genotype data from the previous '.ped' file, but in binary format.
* '.fam': file This includes the first six columns from the previous '.ped' file.
* '.bim' file This is the same as the previous '.map' file, but also includes an additional two columns with the alleles names (which are otherwise lost when'converting the genotype data from .ped file to .bed file.)

To create a set of binary format files for the 'genstudy' dataset:
```{bash, eval=FALSE}
plink --file genstudy --make-bed --out genstudy --noweb
```

To use the binary format files instead of the .ped and .map files, we just substitute the option --file with --bfile in the PLINK command line:
```{bash, eval=FALSE}
plink --bfile genstudy --chr 10 --noweb
```


### Sample QC
In this section, we will start undertaking genotype QC on the 'genstudy' dataset – starting first of all with sample QC, one step at a time.

#### Checks for missing data

To obtain a summary of the amount of missing genotype data per sample and per SNP, use the option '- -missing' in the PLINK command line.

```{bash, eval=FALSE}
plink --bfile genstudy --missing --out genstudy.CRstats --noweb
```

Adding the '--out genstudy.CRstats' option ensures that the two output files are called 'genstudy.CRstats.imiss' and 'genstudy.CRstats.lmiss' respectively.

This command creates two output files:

* a '.imiss' file: summarises the proportion of missing genotype data per individual (one row per individual and six columns). The most important column for sample QC purposes is column 6, which contains the proportion of missing genotypes for the individual.
* a '.lmiss' file: summarises the proportion of missing genotype data per SNP (one row per SNP and five columns). The most important column for SNP QC purposes is column 5, which contains the proportion of missing genotypes for the SNP.

#### Gender Checks

PLINK allows to use genotype data from the X chromosome to determine gender (i.e. based on heterozygosity rates), and compares this to reported gender as per the .ped/.fam file. PLINK then flags any discrepancies i.e. individuals for whom reported gender does not match the gender estimated based on genotype data.
To undertake this comparison, we can use the option '- - check-sex' in PLINK. 

To undertake the gender comparison and save results in an output file called 'genstudy.sexcheck':
```{bash, eval=FALSE}
plink --bfile genstudy --check-sex --out genstudy --noweb
```

The output file has six columns, being the most important one (for the purpose of sample QC) column 5, which indicates whether there is a gender discordance or not.

#### Duplicate/related samples

PLINK will also calculated identity-by-state (IBS) and identity-by-descent (IBD) statistics for our individuals to help us identify duplicated and/or related samples. Before we ask PLINK to do this, however, we need to generate a pruned subset of SNPs using the option '--indep-pairwise' in PLINK, which is based on pairwise genotypic correlation. An example of a command line for generating a pruned subset of SNPs is as follows:
```{bash, eval=FALSE}
plink --bfile genstudy --indep-pairwise 1500 150 0.2 --noweb
```

The options 1500, 150 and 0.2 in the command above relate to the following steps, and of course these options can be changed depending on your requirements:

* consider a window of 1500 SNPs,
* calculate LD between each pair of SNPs in the window, remove one of a pair of SNPs if the LD is greater than 0.2,
* shift the window 150 SNPs forward and repeat the procedure

Running this command line will create two output files, 'plink.prune.in' and 'plink.prune.out':

* plink.prune.in: lists all SNPs remaining after pruning
* plink.prune.out: lists all SNPs removed during pruning

Both these files can subsequently be specified as the argument for PLINK’s '--extract' or '--exclude' command respectively to provide a pruned set of SNPs.

To create a pruned version of the 'genstudy' dataset and call it 'p.genstudy':
```{bash, eval=FALSE}
plink --bfile genstudy --extract plink.prune.in --make-bed --out p.genstudy --noweb
```

To generate IBS and IBD estimates for all pairs of individuals, use the PLINK option '—genome':
```{bash, eval=FALSE}
plink --bfile p.genstudy --genome --out genstudy --noweb
```

Running this command creates an output file called "genstudy.genome". This includes a row per each unique pair of individuals, and fourteen columns, being the most important for the purpose of sample QC column 10, as it includes an estimate of the IBD proportion between individuals.

#### Heterozygosity

To run heterozygosity checks in PLINK, we can use the option '- -het':
```{bash, eval=FALSE}
plink --bfile genstudy --het --out genstudy
```

This command produces the output file "genstudy.het", which contains one row per individual and six columns. Column 6 includes the estimate of the inbreeding coefficient, F.

#### Removing individuals who fail sample QC

To remove individuals who fail any of the QC steps above.
 
##### Removing due to missingness

To investigate how many individuals are excluded at difference threshold levels (e.g. 1%, 5%, and 10%):
```{bash, eval=FALSE}
awk 'NR>1 && $6 >= 0.01 {print}' genstudy.CRstats.imiss | wc -l
awk 'NR>1 && $6 >= 0.05 {print}' genstudy.CRstats.imiss | wc -l
awk 'NR>1 && $6 >= 0.1 {print}' genstudy.CRstats.imiss | wc -l
```

To exclude all individuals with more than 5% missing data:
```{bash, eval=FALSE}
awk '$6 >= 0.05 {print}' genstudy.CRstats.imiss > genstudy.CRremove
plink --bfile genstudy --noweb --remove genstudy.CRremove --make-bed --out genstudy.CR
```

##### Removing due to gender discordance

To select only those individuals with an entry of 'PROBLEM' in column 5:

```{bash, eval=FALSE}
awk '$5=="PROBLEM"{print}' genstudy.sexcheck>genstudy.sexremove
```

To remove these individuals from the 'genstudy.CR' dataset, and create a new dataset named 'genstudy.sex':
```{bash, eval=FALSE}
plink --bfile genstudy.CR --noweb --remove genstudy.sexremove --make-bed --out genstudy.sex
```


##### Remove duplicates and related samples

We use an IBD threshold of 0.1875 to filter out either duplicated or closely related samples (column 10).
```{bash, eval=FALSE}
awk '$10 >= 0.1875 {print}' genstudy.genome > genstudy.PIremove
```

To remove this list of individuals from the 'genstudy.sex' dataset and create a new dataset 'genstudy_sampleqc':
```{bash, eval=FALSE}
plink --bfile genstudy.sex --noweb --remove genstudy.PIremove.list --make-bed --out genstudy_sampleqc
```

##### Heterozygosity
Look at the "genstudy.Het_vs_imiss.pdf" and see if outliers exist. If not, there are no samples to remove.


#### SNP QC

##### Checks for missing data
Similar to what we did for sample QC, we can investigate how many SNPs fail different missingness thresholds by filtering column 5 in 'genstudy_sampleqc.CRstats.lmiss' using different threshold values. We can do this using the following command (e.g. for threshold of 1%):

```{bash, eval=FALSE}
plink --bfile genstudy_sampleqc --missing --out genstudy_sampleqc.CRstats --noweb
awk 'NR>1 && $5 >= 0.01 {print}' genstudy_sampleqc.CRstats.lmiss | wc -l
```

##### Checks for minor allele frequency (MAF)

To investigate how many SNPs have MAF<1% by first of all running the '--freq' option in PLINK:

```{bash, eval=FALSE}
plink --bfile genstudy_sampleqc --noweb --freq --out genstudy_sampleqc
awk '$5<0.01' genstudy_sampleqc.frq | wc -l
```

NOTE: Data quality tends to decrease with decreasing MAF. A low MAF implies rare genotypes which will be seen only a few times in your GWAS dataset. This in turn implies that there is less information that a genotype calling algorithm can use to call this genotype, and so calls are less certain. And the power to detect an association signal decreases with decreasing MAF. However, if a large MAF threshold is selected, this implies more SNPs are removed from study which possibly includes the true causal SNPs. A moderate MAF such as 0.05 is suggested.

##### Checks for adherence to Hardy-Weinberg Equilibrium

To generate a list of genotype counts and Hardy-Weinberg test statistics for each SNP:

```{bash, eval=FALSE}
plink --bfile genstudy_sampleqc --noweb --hardy --out genstudy_sampleqc
```

This provides and output file 'genstudy.hwe' and the p-value for the test for Hardy-Weindberg Equilibrium is in column 9 of this file.

To see how many SNPs have HWE p-value<0.0001 (in controls "UNAFF") and pvalue<0.00001:
```{bash, eval=FALSE}
awk '$3=="UNAFF" && $9<0.0001' genstudy_sampleqc.hwe | wc -l
awk '$3=="UNAFF" && $9<0.00001' genstudy_sampleqc.hwe | wc -l
```

To apply some extra SNP QC filters to our already sample-QC'd dataset:

* Minor allele frequency (MAF) >0.05 – option '--maf 0.05'
* SNP genotyping rate >95% (i.e. <5% missing genotypes for the SNP, across all individuals) – option '-- geno 0.05'
* Hardy-Weinberg p-value >0.0001 in controls – option '-- hwe 0.0001'

```{bash, eval=FALSE}
plink --bfile genstudy_sampleqc --noweb --maf 0.05 --geno 0.05 --hwe 0.0001 --make-bed --out genstudy_qc
```

## Testing for Associations

In this section, we will undertake an analysis of association:

* first, with no adjustment made for non-genetic variables (univariate analysis of association)
* then, with adjustment made for relevant non-genetic variables (multiple regression analysis)

### Software and datasets

We will use the QC'd PLINK files (generated in the previous section) ready to run the analyses of association.

To run the analyses of association, we use a software package called 'SNPTEST (Version 2)' – it's free and available for the analysis of genome-wide association studies.

To use SNPTEST, input files need to be in a specific format:

* one '.gen' file including genotype data, which includes one row per SNP.
* one '.sample' file including phenotypic data. It has three parts (a) a header line detailing the names of the columns in the file, (b) a line detailing the types of variables stored in each column, and (c) a line for each individual including the information for that individual.

A '.gen' file includes one row per SNP. The first five entries on each line should be as follows:

* SNP ID: This entry is usually used to denote the chromosome number.
* rs number: This entry is a number which uniquely identifies the genotyped SNP. An rs number is an accession number used by researchers and databases to refer to specific SNPs. It stands for 'Reference SNP cluster ID'.
* Base pair position of the SNP: A value that described the SNP’s position on the chromosome.
* Allele coded A (see below for further explanation of this): The entry here will be A, C, T or G i.e. corresponding to the four possible nucleotides.
* Allele coded B (see below for further explanation of this): The entry here will be A, C, T or G i.e. corresponding to the four possible nucleotides.

The remaining entries on each row represent the genotype of each individual at the SNP. Each individual will have three entries, representing their probability of having the 'AA', 'AB' and 'BB' genotypes respectively. As we do not have any imputed SNPs in the current dataset, the probability for each genotype will be either 0 or 1. So, an individual with genotype AA will be coded '1 0 0', with genotype AB will be coded '0 1 0', and with genotype BB will be coded '0 0 1'. If genotype is missing for an individual, all three entries are set to '0 0 0'.

It is possible to convert QC'd PLINK files to '.gen' and '.sample' format using a program called 'GTOOL'. 
We have also removed all chromosome X SNPs from these files, since in terms of association we are only interested in SNPs on chromosome 10.


### Univariate analyses of association

To run univariate analyses of association between all SNPs in our 'genstudy_qc' file and our phenotype 'diseased', assuming an additive mode of inheritance, we would use the following SNPtest command:

```{bash, eval=FALSE}
snptest \
-data genstudy_qc.gen genstudy_qc.sample \
-o genstudy_qc_univariate_add.out \
-pheno diseased \
-frequentist 1 \
-method threshold
```

Due to the large number of output columns in 'genstudy_qc_univariate_dom.out' and the large number of SNPs investigated, it is useful to look at our results in summary format. A useful way of doing this is by preparing a Manhattan plot to give a graphical representation of our results. Essentially, this is a plot of pvalue versus base pair position for each SNP and is a useful way of identifying significantly associated SNPs.

First of all, it is necessary to re-format our output file into a format which is appropriate for the shell script.

1. Add chromosome number to each row (also need to delete final row in datafile since includes an additional line of text which is not needed)
```{bash, eval=FALSE}
awk 'NR>11{$1=10; print}' genstudy_qc_univariate_add.out >genstudy_qc_new.out
sed '$d' genstudy_qc_new.out>genstudy_qc_new2.out
```

2. Select only columns of interest, and label them:
```{bash, eval=FALSE}
echo "CHR SNP BP P" > genstudy_qc_Manhattan.txt;
awk '{print $1,$2,$4,$42}' genstudy_qc_new2.out >>genstudy_qc_Manhattan.txt
```

3. Create a new file (“genstudy_qc.unimp.snp”) which lists all actually genotyped SNPs.
```{bash, eval=FALSE}
awk ' $9==1{print $2}' genstudy_qc_univariate_add.out > genstudy_qc.unimp.snp
```

4. Now, the data is prepared for generating the Manhattan plot.


To prepare a Q-Q plot of your results to ensure that there is no apparent genomic inflation in your results, which would suggest population substructure:

```{r, eval=FALSE}
pvals <- read.table("genstudy_qc_Manhattan.txt", header=T)
observed <- sort(pvals$P)
lobs <- -(log10(observed))
expected <- c(1:length(observed))
lexp <- -(log10(expected / (length(expected)+1)))
pdf("qqplot.pdf", width=6, height=6)
plot(c(0,7), c(0,7), col="red", lwd=3, type="l", xlab="Expected (-logP)", ylab="Observed (-logP)",
xlim=c(0,7), ylim=c(0,7), las=1, xaxs="i", yaxs="i", bty="l")
points(lexp, lobs, pch=23, cex=.4, bg="black")
dev.off()
```

To extract a list of the SNPs giving the lowest p-values:
```{bash, eval=FALSE}
awk ' $4 <0.0001' genstudy_qc_Manhattan.txt > lowest_ps_univariate
awk ' $4>0' lowest_ps_univariate > lowest_ps_univariate_new #to filter out SNPs were it was not possible to undertake an analysis of association
```

### Multiple regression analyses

In the 'genstudy.sample' file you will notice four columns to the right of the phenotype column 'diseased'. These are labelled 'age', 'bmi', 'family' and 'sex', and represent four variables believed to be of potential interest in terms of being associated with our disease.

To decide whether to adjust for each of these variables, we first of all need to test whether they are univariately associated with our phenotype ‘diseased’. As our phenotype is binary, we can use Student’s t-test to test for association with age and bmi, and the chi-square test to test for association with family history and sex.

```{r, eval=FALSE}
data=read.table("genstudy_qc.sample",header=T)
data=data[-1,]
attach(data)
res_age=t.test(as.numeric(age)~diseased)
res_bmi=t.test(as.numeric(bmi)~diseased)
res_family=chisq.test(family,diseased)
res_sex=chisq.test(sex,diseased)
res_age$p.value
res_bmi$p.value
res_family$p.value
res_sex$p.value
```

To now run our SNP association analyses using a multiple regression approach, we can add the element '-cov_names' followed by the clinical variable
names to your command (assuming that we have decided to adjust for all clinical variables giving p<0.05 in our univariate analysis, we only have to adjust for age and family history):

```{bash, eval=FALSE}
snptest \
-data genstudy_qc.gen genstudy_qc.sample \
-o genstudy_qc_adjusted_add.out \
-pheno diseased \
-frequentist 1 \
-method threshold \
-cov_names age family
```

To prepare a Manhattan plot and QQ-plot of the results from your multiple regression analysis by adjusting the code used for plotting the univariate results:

```{bash, eval=FALSE}
awk 'NR>11{$1=10; print}' genstudy_qc_adjusted_add.out > genstudy_qc_new.out
sed '$d' genstudy_qc_new.out > genstudy_qc_new2.out
tail -n +2 genstudy_qc_new2.out > genstudy_qc_new3.out
echo "CHR SNP BP P" > genstudy_qc_adj_Manhattan.txt
awk '{print $1,$2,$4,$42}' genstudy_qc_new3.out >> genstudy_qc_adj_Manhattan.txt
awk '$9==1{print $2}' genstudy_qc_adjusted_add.out > genstudy_qc.adj.snp
sh QuickManhattan.sh
```

To obtain a list of the lowest p-values from this analysis, and compare them with your lowest pvalues from the univariate analysis:

```{bash, eval=FALSE}
awk ' $4 <0.0001' genstudy_qc_adj_Manhattan.txt > lowest_ps_adjusted
awk '$4>0' lowest_ps_adjusted > lowest_ps_adjusted_new
cat lowest_ps_adjusted_new
```

## Population structure in GWAS

### Testing for association under an additive model

To test for association under an additive model using the PLINK command, but without adjustment for any covariates: 

```{bash, eval=FALSE}
plink --noweb --bfile EGCUT.clean --logistic --ci 0.95 --out plink.additive
```

To investigate the impact of population structure by generating a QQ plot of observed p-values against those that would be expected under the null hypothesis of no association. In the absence of population structure, we would expect most points to lie on the y=x line:

```{bash, eval=FALSE}
R --vanilla --slave --args plink.additive.assoc.logistic ADD qq_1.pdf < qqPlot.R
```

### Performing multi-dimensional scaling

Multi-dimensional scaling in PLINK is performed in three steps: 

1. Identifying a subset of "independent" common SNPs (minor allele frequency of at least 5%) that are not in linkage disequilibrium with each other. 
```{bash, eval=FALSE}
plink --noweb --bfile EGCUT.clean --maf 0.05 --indep-pairwise 50 5 0.05
```

2. Calculating the relatedness between each pair of individuals using the set of independent SNPs which is a measure of genetic similarity. 
```{bash, eval=FALSE}
plink --noweb --bfile EGCUT.clean --extract plink.prune.in --Z-genome
```

3. Perform multi-dimensional scaling using the relatedness matrix.
```{bash, eval=FALSE}
plink --noweb --bfile EGCUT.clean --read-genome plink.genome.gz --cluster --mds-plot 2
```

Note that the option --Z-genome produces a compressed genome file and saves on storage. The option --mds-plot specifies how many eigenvectors from the multi-dimensional scaling to summarise in the output file. The eigenvectors are output to the file plink.mds.


The output file has one row per individual, and provides the identifier used in the PLINK family file, together with the first two eigenvectors (columns C1 and C2). You can plot the first two eigenvectors against each other using the command:

```{bash, eval=FALSE}
R --vanilla --slave --args plink.mds EGCUT.clean.fam mds.pdf < mds.R
```

In the output plot, each point corresponds to an individual.


### Testing for association under an additive model with adjustment for confounding

To account for population structure in our analysis, we can repeat our test of association under and additive model, but this type adjusting for eigenvectors from the multi-dimensional scaling as covariates:

```{bash, eval=FALSE}
plink --noweb --bfile EGCUT.clean --logistic --covar plink.mds --covar-name C1,C2 --ci 0.95 --out plink.additive.mds
```

To investigate the impact of population structure that is not accounted for by the first two eigenvectors from multi-dimensional scaling by generating a QQ plot with the command:

```{bash, eval=FALSE}
R --vanilla --slave --args plink.additive.mds.assoc.logistic ADD qq_2.pdf < qqPlot.R
```

To obtain association summary statistics for the SNP:

```{bash, eval=FALSE}
grep SNPID plink.additive.mds.assoc.logistic
```


## Phasing and Imputation

By utilising genotype imputation methods, we can investigate whether there are neighbouring SNPs to a particular SNP that generated a significant p-value, also sharing evidence of association with the phenotype. 
The focus in this section will be on imputing genotypes within close proximity of a significant SNP, and then to re-run the association analyses on the imputed dataset.

### Pre-phasing and imputation

Prior to undertaking genotype imputation, it is necessary to "pre-phase" the genotype data to convert it into haplotype form.

Doing this affords more efficient imputation as the reference panels on which we base our imputation are all in haplotype form as well. Haplotypes span across many locus so it is important that when focusing in on a certain region of the genome, (for example the region surrounding a significant SNP as we are in this practical), that we allow a sufficient buffer zone around the region. If we didn’t allow this buffer zone then we could interrupt haplotype construction with the locus of interest!

To undertake the pre-phasing we use a software package called SHAPEIT2 (https://mathgen.stats.ox.ac.uk/genetics_software/shapeit/shapeit.htm).

The causal SNP we found before had base pair position 64803579 and so a sensible region to pre-phase might be from 63Mb to 68Mb, which will include the immediate region surrounding the causal SNP, plus a buffer region at either end. 

To pre-phase the "genstudy_pp" dataset, we can run the following SHAPEIT2 command:

```{bash, eval=FALSE}
shapeit --input-ped genstudy_pp.ped genstudy_pp.map --input-map chr10.map --output-max genstudy.ph --thread 2 --input-from 63000000 --input-to 68000000
```

Once we have pre-phased our data, we can undertake genotype imputation and to do this we will use a software package called "IMPUTE2" (https://mathgen.stats.ox.ac.uk/impute/impute_v2.html).

After running SHAPEIT2 on the "genstudy_pp" dataset, we obtained a "genstudy.ph.haps" datafile which contained phased haplotypes for our specified region. We can now run IMPUTE2 on this .haps datafile to impute genotypes at SNPs not originally genotyped, but included on our chosen reference panel. For the purpose of this practical, we will use the reference panel from the 1000 Genomes Project (http://www.1000genomes.org). To do this, we can use the following IMPUTE2 command:

```{bash, eval=FALSE}
impute2 -use_prephased_g -known_haps_g genstudy.ph.haps -m chr10.map -h chr10.haps.gz -l chr10.leg.gz -int 64300000 65300000 -Ne 20000 -buffer 500 -o genstudy_imp.gen
```

Please note that the interval we specify under the option "-int" (64300000 to 65300000) is narrower than the one we specified in the SHAPEIT2 command. This is because the imputation process will produce genotypes rather than haplotypes. Therefore we can narrow down to a 1Mb region of interest.

After the Imputation has run, in the screen output there is a section called "Imputation accuracy assessment". The interval here denotes the probability range at which a SNP genotype has been called and the concordance with the patient genotypes. These figures can be improved by increasing the number of patients in the study or with better match reference haplotypes.

### Re-running our univariate analyses of association

Previously, when we were dealing only with actually genotyped SNPs, our .gen file ("genstudy_qc.gen") included the first five compulsory columns, followed by three columns for each genotyped SNP. The three columns represented an individual's probability of having the "AA", "AB" and "BB" genotypes respectively. As we did not have any imputed SNPs, the probability for each genotype was either 0 or 1. However, now that we are dealing with imputed SNPs, the probability for each genotype can be any number between 0 and 1, representing our genotype uncertainty.

```{bash, eval=FALSE}
head -n 1 genstudy_imp.gen
```

Please, notice that there are number others than 0 and 1 in the columns representing genotype probabilities for the SNPs.

To run univariate analyses of association on a dataset which includes imputed genotypes, we can again use the SNPTest programme. However, the element "method" within the SNPTest command needs to be specified differently. The "method" element controls the way in which genotype uncertainty is accounted for in the analyses of association, bearing in mind that imputation can only provide a ‘best estimate’ of what the true genotype at a SNP would be.

* threshold: Assumes a particular genotype at a SNP only if accuracy of the genotype call is above a given threshold. The calling threshold is controlled by the flag -call_thresh and the default calling threshold is 0.9.
* expected: Uses expected genotype counts, also known as genotype dosages, in the analyses of association.
* score: Uses a missing data likelihood score test in the analyses of association.
* ml: Again uses missing data likelihood approach, but with multiple Newton-Raphson iterations to estimate the parameters in the missing data likelihood.
* em: Again uses missing data likelihood approach, but with an EM algorithm to estimate the parameters in the missing data likelihood.

So, to run a univariate analysis of association on our imputed dataset, assuming the threshold method we would use the following command:

```{bash, eval=FALSE}
snptest -data genstudy_imp.gen genstudy_qc.sample -o genstudy_qc_univariate_add.imp.out -pheno diseased -frequentist 1 -method threshold
```

The SNPtest output file "genstudy_qc_univariate_add.imp.out" can now be scrutinised in much the same way as we did for the output file initially – i.e. we can produce Manhattan and QQ plots of the resulting p-values – except for one additional and important QC step which needs to occur post-imputation. This QC step involves filtering out SNPs with poor imputation accuracy. The SNPtest output file has a column labelled "INFO", which contains, for each SNP, a number indicating how accurately it has been imputed. The value of INFO will range from 0 (no certainty in imputation) to 1 (perfect accuracy in imputation/actually genotyped SNP). Poorly imputed SNPs are likely to contribute to false positive results whilst removing a large number of imputed SNPs will distort the overall results. Therefore, as a QC step we need to identify an appropriate, yet not too stringent, threshold for the level of accuracy that is allowed. Unfortunately, there is no exact science to choosing the threshold; the SNPtest website (https://mathgen.stats.ox.ac.uk/impute/impute_v2.html) views INFO thresholds between 0.3 and 0.5 as reasonable. For this analysis we will utilise an INFO threshold of 0.4.

This additional QC step can be implemented very easily by:

```{bash, eval=FALSE}
awk 'NR>11&&$9>0.4{$1=10;print}' genstudy_qc_univariate_add.imp.out >genstudy_qc_new.imp.out
```
# Linear Models

## Introduction

What is a **linear model**? We might have heard about it countless times but, do we really know what is a linear model and what is its purpose? In this post, we will try to find out to find the answers to these questions.

Before going deeper into the linear model's details, you may first want to have a look at the [[Machine Learning Terminology|Machine Learning Terminology]] post. 

<!-- This post has been created following an example given in the first chapter of the [Pattern Recognition and Machine Learning](https://www.springer.com/gp/book/9780387310732) book, whose author is Christofer Bishop. -->

<!-- ## Introducing the problem -->

<!-- Let's imagine a simple regression problem where we are given a training dataset formed by N observations of *x* (the input vector *x*) and their corresponding target values *y* (the target vector *y*). Additionally, let's suppose that: -->

<!-- * The training dataset comprises N = 10 values. -->
<!-- * All values of x have been chosen for n = 1, . . . , N, spaced uniformly in range [0, 1]. This means that our *x* input vector will be equal to: ![function_linearmodels_1](https://github.com/SoniaRuiz/blog/blob/master/images/function_linearmodels_1.gif) -->
<!-- * The target vector in this example has been generated by the following function: ![function_linearmodels](https://github.com/SoniaRuiz/blog/blob/master/images/function_linearmodels.gif) -->

<!-- Our main aim in this problem will be to try to make accurate predictions of *y* given a particular *x* value. Please, notice that it involves discovering the underlying function ![function_linearmodels](https://github.com/SoniaRuiz/blog/blob/master/images/function_linearmodels.gif). This can become a difficult problem because of two main reasons: -->

<!-- * Our training set is not infinite: our input vector *x* comprises only 10 values (N=10). -->
<!-- * Our training dataset might also be corrupted by noise. -->

<!-- ## Using linear models to solve the problem -->

<!-- Let's consider a simple approach based on curve fitting. In particular, we will use a polynomial function of the form: -->

<!-- ![function_linearmodels_2](https://github.com/SoniaRuiz/blog/blob/master/images/function_linearmodels_2.gif) -->

<!-- This polynomial function ![function_linearmodels_3](https://github.com/SoniaRuiz/blog/blob/master/images/function_linearmodels_3.gif) is a *nonlinear function* of *x* (because all *x* values are raised to the power of *j*) and a *linear function* of the coefficients *w*. In other words, this function is linear in the unknown parameters (we are not given an input vector of *w*). Functions, such as polynomials, are called **linear models**. -->

<!-- ### Determining the values of the coefficients -->

<!-- The values of the coefficients (*w*) can be discovered by minimizing an error function that measures the misfit between the function ![function_linearmodels_3](https://github.com/SoniaRuiz/blog/blob/master/images/function_linearmodels_3.gif), for any given value of w, and the training set data points. -->

<!-- Which kind of error function shall we choose? Let's try it first with the sum of the squares of the errors between the predictions ![function_linearmodels_4](https://github.com/SoniaRuiz/blog/blob/master/images/function_linearmodels_4.gif) for each input *x* value and its corresponding target figure *t* so that we minimize: -->

<!-- ![function_linearmodels_5](https://github.com/SoniaRuiz/blog/blob/master/images/function_linearmodels_5.gif) -->

<!-- The following image might be useful to visualize the overall problem. The *x* axis represents all data points from the input vector whereas the *y* axis represents the target figures corresponding to each x value. The red curve is the result of the function ![function_linearmodels_4](https://github.com/SoniaRuiz/blog/blob/master/images/function_linearmodels_4.gif) and each vertical green bar is showing the error function: (one half of) the displacements of each data point from the function ![function_linearmodels_4](https://github.com/SoniaRuiz/blog/blob/master/images/function_linearmodels_4.gif). Our aim is **to reduce the size of each green bar to the minimum**, so we could finally asses the hidden function ![function_linearmodels](https://github.com/SoniaRuiz/blog/blob/master/images/function_linearmodels.gif). -->

<!-- ![function_linearmodels_6](https://github.com/SoniaRuiz/blog/blob/master/images/function_linearmodels_6.PNG). -->
